{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f59f4b53-e31a-46b4-8de2-21d718775ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as tch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d69d6b-f0d8-4322-8c9a-d3ade0af0415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names=[\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\n",
    "          \"num_failed_logins\",\"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\n",
    "          \"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\n",
    "          \"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\", \n",
    "          \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\n",
    "          \"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"attack\",\"difficulty_level\"]\n",
    "len(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e332216c-8306-4150-84b9-8048a05008ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='attack'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=pd.read_csv(\"KDDTrain+.txt\",header=None,names=col_names)\n",
    "data.head()\n",
    "data.loc[data['attack'] ==\"normal\", 'attack'] = 0\n",
    "data.loc[data['attack'] !=0, 'attack'] = 1\n",
    "data['attack'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f5cc82b-53f0-4333-97f9-60e2005ae51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0        491          0     0               0       0    0   \n",
       "1         0        146          0     0               0       0    0   \n",
       "2         0          0          0     0               0       0    0   \n",
       "3         0        232       8153     0               0       0    0   \n",
       "4         0        199        420     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
       "0                  0          0                0  ...     False      False   \n",
       "1                  0          0                0  ...     False      False   \n",
       "2                  0          0                0  ...     False      False   \n",
       "3                  0          1                0  ...     False      False   \n",
       "4                  0          1                0  ...     False      False   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0        False      False    False    False    False    False     True   \n",
       "1        False      False    False    False    False    False     True   \n",
       "2        False      False     True    False    False    False    False   \n",
       "3        False      False    False    False    False    False     True   \n",
       "4        False      False    False    False    False    False     True   \n",
       "\n",
       "   flag_SH  \n",
       "0    False  \n",
       "1    False  \n",
       "2    False  \n",
       "3    False  \n",
       "4    False  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.astype({'attack':'int'})\n",
    "enc_Data=pd.get_dummies(data)\n",
    "enc_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b385930a-1c4d-4070-a663-6af15b425d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_real=enc_Data.drop([\"attack\"],axis=1)\n",
    "Y_train_real=enc_Data[\"attack\"]\n",
    "from sklearn import preprocessing\n",
    "x = X_train_real.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "normalized_df= pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ff61c5d-b0a8-402a-9ba2-a6359abe8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=normalized_df.to_numpy()\n",
    "Y=Y_train_real.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02baee82-de7a-4799-989c-224d838ed491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train, y_train= ros.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "933c4635-e6ad-4544-a6aa-1b6639dbd277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134686, 123) (134686,)\n",
      "(125973, 123) (125973,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cce0bf31-e6fb-400c-b870-cf4b0bc06b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 67343, 1: 67343})\n",
      "Counter({0: 67343, 1: 58630})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_train))\n",
    "print(Counter(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6290b880-d8fd-4496-b933-6451fa8ebe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest=pd.read_csv(\"KDDTest+.txt\",header=None,names=col_names)\n",
    "datatest.loc[datatest['attack'] ==\"normal\", 'attack'] = 0\n",
    "datatest.loc[datatest['attack'] !=0, 'attack'] = 1\n",
    "datatest = datatest.astype({'attack':'int'})\n",
    "\n",
    "enc_test=pd.get_dummies(datatest)\n",
    "X_test=enc_Data.drop([\"attack\"],axis=1)\n",
    "Y_test=enc_Data[\"attack\"]\n",
    "from sklearn import preprocessing\n",
    "x = X_test.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_test_Scaled = min_max_scaler.fit_transform(x)\n",
    "normalized_df_test= pd.DataFrame(x_test_Scaled)\n",
    "\n",
    "X_te=normalized_df_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93c00368-5bc0-4a99-a39e-2969e2e2cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_te = np.reshape(X_te, (X_te.shape[0], X_te.shape[1], 1))\n",
    "#X_t[1].shape\n",
    "\n",
    "#y_train.shape\n",
    "y_test=Y_test.to_numpy()\n",
    "#y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38514491-baa3-48f7-b6ee-27cbb3d7a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # initializing model\n",
    "# input layer and first layer with 50 neurons\n",
    "model.add(Conv1D(32, 3, padding=\"same\",input_shape = (X_t.shape[1], 1), activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=(4)))  \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(32, 3, padding=\"same\", activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=(4)))  \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=50))\n",
    "# output layer with softmax activation\n",
    "model.add(Dense(units=1,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cbdb866-03bc-4dbb-98ed-a92ed71a38c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d08d4e86-507f-48a4-94fb-d8afd81cf62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 123, 32)           128       \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 30, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 30, 32)            0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 30, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 7, 32)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 7, 32)             0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 224)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                11250     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14533 (56.77 KB)\n",
      "Trainable params: 14533 (56.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58d55bf9-52b9-4918-9d51-90a16e6f81c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 17s 638ms/step - loss: 0.5263 - accuracy: 0.4658 - val_loss: 0.3683 - val_accuracy: 0.6368\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 13s 576ms/step - loss: 0.3090 - accuracy: 0.4658 - val_loss: 0.2412 - val_accuracy: 0.6368\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 12s 547ms/step - loss: 0.2247 - accuracy: 0.4658 - val_loss: 0.1896 - val_accuracy: 0.6368\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 12s 529ms/step - loss: 0.1815 - accuracy: 0.4658 - val_loss: 0.1598 - val_accuracy: 0.6368\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 11s 523ms/step - loss: 0.1552 - accuracy: 0.4658 - val_loss: 0.1354 - val_accuracy: 0.6368\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 12s 524ms/step - loss: 0.1356 - accuracy: 0.4658 - val_loss: 0.1177 - val_accuracy: 0.6368\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 0.1241 - accuracy: 0.4658 - val_loss: 0.1093 - val_accuracy: 0.6368\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 12s 526ms/step - loss: 0.1151 - accuracy: 0.4658 - val_loss: 0.1011 - val_accuracy: 0.6368\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 12s 546ms/step - loss: 0.1073 - accuracy: 0.4658 - val_loss: 0.0953 - val_accuracy: 0.6368\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 12s 532ms/step - loss: 0.1019 - accuracy: 0.4658 - val_loss: 0.0889 - val_accuracy: 0.6368\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.0969 - accuracy: 0.4658 - val_loss: 0.0829 - val_accuracy: 0.6368\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 12s 537ms/step - loss: 0.0919 - accuracy: 0.4658 - val_loss: 0.0772 - val_accuracy: 0.6368\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 0.0877 - accuracy: 0.4658 - val_loss: 0.0724 - val_accuracy: 0.6368\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 12s 541ms/step - loss: 0.0842 - accuracy: 0.4658 - val_loss: 0.0676 - val_accuracy: 0.6368\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 12s 534ms/step - loss: 0.0786 - accuracy: 0.4658 - val_loss: 0.0619 - val_accuracy: 0.6368\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 12s 531ms/step - loss: 0.0753 - accuracy: 0.4658 - val_loss: 0.0588 - val_accuracy: 0.6368\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 12s 537ms/step - loss: 0.0718 - accuracy: 0.4658 - val_loss: 0.0566 - val_accuracy: 0.6368\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 12s 545ms/step - loss: 0.0693 - accuracy: 0.4658 - val_loss: 0.0537 - val_accuracy: 0.6368\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 14s 621ms/step - loss: 0.0666 - accuracy: 0.4658 - val_loss: 0.0515 - val_accuracy: 0.6368\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 15s 670ms/step - loss: 0.0637 - accuracy: 0.4658 - val_loss: 0.0479 - val_accuracy: 0.6368\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 15s 698ms/step - loss: 0.0615 - accuracy: 0.4658 - val_loss: 0.0448 - val_accuracy: 0.6368\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 15s 660ms/step - loss: 0.0599 - accuracy: 0.4658 - val_loss: 0.0445 - val_accuracy: 0.6368\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 14s 621ms/step - loss: 0.0582 - accuracy: 0.4658 - val_loss: 0.0417 - val_accuracy: 0.6368\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 14s 651ms/step - loss: 0.0568 - accuracy: 0.4658 - val_loss: 0.0421 - val_accuracy: 0.6368\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 13s 597ms/step - loss: 0.0550 - accuracy: 0.4658 - val_loss: 0.0412 - val_accuracy: 0.6368\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 13s 569ms/step - loss: 0.0536 - accuracy: 0.4658 - val_loss: 0.0393 - val_accuracy: 0.6368\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 13s 616ms/step - loss: 0.0524 - accuracy: 0.4658 - val_loss: 0.0386 - val_accuracy: 0.6368\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 13s 590ms/step - loss: 0.0509 - accuracy: 0.4658 - val_loss: 0.0381 - val_accuracy: 0.6368\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 14s 656ms/step - loss: 0.0507 - accuracy: 0.4658 - val_loss: 0.0368 - val_accuracy: 0.6368\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 17s 782ms/step - loss: 0.0492 - accuracy: 0.4658 - val_loss: 0.0372 - val_accuracy: 0.6368\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 15s 687ms/step - loss: 0.0492 - accuracy: 0.4658 - val_loss: 0.0349 - val_accuracy: 0.6368\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 15s 690ms/step - loss: 0.0482 - accuracy: 0.4658 - val_loss: 0.0347 - val_accuracy: 0.6368\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 15s 668ms/step - loss: 0.0468 - accuracy: 0.4658 - val_loss: 0.0332 - val_accuracy: 0.6368\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 14s 636ms/step - loss: 0.0457 - accuracy: 0.4658 - val_loss: 0.0326 - val_accuracy: 0.6368\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 14s 650ms/step - loss: 0.0463 - accuracy: 0.4658 - val_loss: 0.0331 - val_accuracy: 0.6368\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 13s 584ms/step - loss: 0.0452 - accuracy: 0.4658 - val_loss: 0.0315 - val_accuracy: 0.6368\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 13s 596ms/step - loss: 0.0445 - accuracy: 0.4658 - val_loss: 0.0332 - val_accuracy: 0.6368\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 13s 598ms/step - loss: 0.0437 - accuracy: 0.4658 - val_loss: 0.0321 - val_accuracy: 0.6368\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 13s 598ms/step - loss: 0.0434 - accuracy: 0.4658 - val_loss: 0.0331 - val_accuracy: 0.6368\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 13s 600ms/step - loss: 0.0425 - accuracy: 0.4658 - val_loss: 0.0307 - val_accuracy: 0.6368\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 18s 829ms/step - loss: 0.0420 - accuracy: 0.4658 - val_loss: 0.0294 - val_accuracy: 0.6368\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 18s 832ms/step - loss: 0.0410 - accuracy: 0.4658 - val_loss: 0.0290 - val_accuracy: 0.6368\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 18s 829ms/step - loss: 0.0405 - accuracy: 0.4658 - val_loss: 0.0288 - val_accuracy: 0.6368\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 18s 803ms/step - loss: 0.0400 - accuracy: 0.4658 - val_loss: 0.0275 - val_accuracy: 0.6368\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 18s 825ms/step - loss: 0.0403 - accuracy: 0.4658 - val_loss: 0.0265 - val_accuracy: 0.6368\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 19s 862ms/step - loss: 0.0400 - accuracy: 0.4658 - val_loss: 0.0277 - val_accuracy: 0.6368\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 19s 841ms/step - loss: 0.0404 - accuracy: 0.4658 - val_loss: 0.0257 - val_accuracy: 0.6368\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 18s 834ms/step - loss: 0.0392 - accuracy: 0.4658 - val_loss: 0.0273 - val_accuracy: 0.6368\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 19s 873ms/step - loss: 0.0387 - accuracy: 0.4658 - val_loss: 0.0258 - val_accuracy: 0.6368\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 19s 850ms/step - loss: 0.0385 - accuracy: 0.4658 - val_loss: 0.0256 - val_accuracy: 0.6368\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 18s 822ms/step - loss: 0.0374 - accuracy: 0.4658 - val_loss: 0.0249 - val_accuracy: 0.6368\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 20s 899ms/step - loss: 0.0378 - accuracy: 0.4658 - val_loss: 0.0241 - val_accuracy: 0.6368\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.0373 - accuracy: 0.4658 - val_loss: 0.0254 - val_accuracy: 0.6368\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 40s 1s/step - loss: 0.0367 - accuracy: 0.4658 - val_loss: 0.0241 - val_accuracy: 0.6368\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 22s 988ms/step - loss: 0.0362 - accuracy: 0.4658 - val_loss: 0.0244 - val_accuracy: 0.6368\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.0357 - accuracy: 0.4658 - val_loss: 0.0253 - val_accuracy: 0.6368\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 25s 1s/step - loss: 0.0357 - accuracy: 0.4658 - val_loss: 0.0236 - val_accuracy: 0.6368\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.0354 - accuracy: 0.4658 - val_loss: 0.0270 - val_accuracy: 0.6368\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.0355 - accuracy: 0.4658 - val_loss: 0.0244 - val_accuracy: 0.6368\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 20s 911ms/step - loss: 0.0352 - accuracy: 0.4658 - val_loss: 0.0244 - val_accuracy: 0.6368\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 20s 904ms/step - loss: 0.0342 - accuracy: 0.4658 - val_loss: 0.0232 - val_accuracy: 0.6368\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.0346 - accuracy: 0.4658 - val_loss: 0.0229 - val_accuracy: 0.6368\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 22s 984ms/step - loss: 0.0343 - accuracy: 0.4658 - val_loss: 0.0214 - val_accuracy: 0.6368\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 20s 928ms/step - loss: 0.0337 - accuracy: 0.4658 - val_loss: 0.0222 - val_accuracy: 0.6368\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 20s 925ms/step - loss: 0.0331 - accuracy: 0.4658 - val_loss: 0.0222 - val_accuracy: 0.6368\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 20s 913ms/step - loss: 0.0340 - accuracy: 0.4658 - val_loss: 0.0223 - val_accuracy: 0.6368\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 21s 980ms/step - loss: 0.0336 - accuracy: 0.4658 - val_loss: 0.0236 - val_accuracy: 0.6368\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.0325 - accuracy: 0.4658 - val_loss: 0.0212 - val_accuracy: 0.6368\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 21s 983ms/step - loss: 0.0335 - accuracy: 0.4658 - val_loss: 0.0204 - val_accuracy: 0.6368\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 21s 959ms/step - loss: 0.0323 - accuracy: 0.4658 - val_loss: 0.0210 - val_accuracy: 0.6368\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 22s 993ms/step - loss: 0.0322 - accuracy: 0.4658 - val_loss: 0.0206 - val_accuracy: 0.6368\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 21s 971ms/step - loss: 0.0331 - accuracy: 0.4658 - val_loss: 0.0200 - val_accuracy: 0.6368\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 21s 934ms/step - loss: 0.0319 - accuracy: 0.4658 - val_loss: 0.0207 - val_accuracy: 0.6368\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 21s 950ms/step - loss: 0.0312 - accuracy: 0.4658 - val_loss: 0.0208 - val_accuracy: 0.6368\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 21s 955ms/step - loss: 0.0312 - accuracy: 0.4658 - val_loss: 0.0194 - val_accuracy: 0.6368\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 21s 965ms/step - loss: 0.0302 - accuracy: 0.4658 - val_loss: 0.0198 - val_accuracy: 0.6368\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.0311 - accuracy: 0.4658 - val_loss: 0.0186 - val_accuracy: 0.6368\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 33s 2s/step - loss: 0.0302 - accuracy: 0.4658 - val_loss: 0.0177 - val_accuracy: 0.6368\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 28s 1s/step - loss: 0.0308 - accuracy: 0.4658 - val_loss: 0.0195 - val_accuracy: 0.6368\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 25s 1s/step - loss: 0.0302 - accuracy: 0.4658 - val_loss: 0.0193 - val_accuracy: 0.6368\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 22s 995ms/step - loss: 0.0301 - accuracy: 0.4658 - val_loss: 0.0191 - val_accuracy: 0.6368\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.0299 - accuracy: 0.4658 - val_loss: 0.0179 - val_accuracy: 0.6368\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 27s 1s/step - loss: 0.0294 - accuracy: 0.4658 - val_loss: 0.0182 - val_accuracy: 0.6368\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.0299 - accuracy: 0.4658 - val_loss: 0.0205 - val_accuracy: 0.6368\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 21s 954ms/step - loss: 0.0293 - accuracy: 0.4658 - val_loss: 0.0199 - val_accuracy: 0.6368\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 16s 704ms/step - loss: 0.0292 - accuracy: 0.4658 - val_loss: 0.0178 - val_accuracy: 0.6368\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 16s 746ms/step - loss: 0.0295 - accuracy: 0.4658 - val_loss: 0.0183 - val_accuracy: 0.6368\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 16s 746ms/step - loss: 0.0293 - accuracy: 0.4658 - val_loss: 0.0177 - val_accuracy: 0.6368\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 16s 741ms/step - loss: 0.0289 - accuracy: 0.4658 - val_loss: 0.0177 - val_accuracy: 0.6368\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 16s 712ms/step - loss: 0.0282 - accuracy: 0.4658 - val_loss: 0.0170 - val_accuracy: 0.6368\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 15s 675ms/step - loss: 0.0288 - accuracy: 0.4658 - val_loss: 0.0168 - val_accuracy: 0.6368\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 10s 432ms/step - loss: 0.0279 - accuracy: 0.4658 - val_loss: 0.0171 - val_accuracy: 0.6368\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 9s 401ms/step - loss: 0.0280 - accuracy: 0.4658 - val_loss: 0.0168 - val_accuracy: 0.6368\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 9s 392ms/step - loss: 0.0280 - accuracy: 0.4658 - val_loss: 0.0160 - val_accuracy: 0.6368\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 9s 392ms/step - loss: 0.0286 - accuracy: 0.4658 - val_loss: 0.0181 - val_accuracy: 0.6368\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 9s 401ms/step - loss: 0.0276 - accuracy: 0.4658 - val_loss: 0.0161 - val_accuracy: 0.6368\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0277 - accuracy: 0.4658 - val_loss: 0.0156 - val_accuracy: 0.6368\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0283 - accuracy: 0.4658 - val_loss: 0.0158 - val_accuracy: 0.6368\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 9s 392ms/step - loss: 0.0281 - accuracy: 0.4658 - val_loss: 0.0162 - val_accuracy: 0.6368\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0279 - accuracy: 0.4658 - val_loss: 0.0161 - val_accuracy: 0.6368\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_t, y_train, epochs=100, batch_size=5000,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d00506aa-4670-43ff-8d93-6996991559f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3937/3937 [==============================] - 10s 3ms/step - loss: 0.0159 - accuracy: 0.4654\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate(X_te, y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
